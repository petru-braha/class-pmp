{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88469248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba24c5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Parameter        Mean  95% CI Lower  95% CI Upper\n",
      "0     alpha  -51.863845   -492.206919    344.731762\n",
      "1     beta1    4.222246      2.018331      6.573542\n",
      "2     beta2  353.883350    280.137470    434.291148\n",
      "3     sigma  503.518293    470.895480    538.999366\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "\n",
    "df = pd.read_csv('Prices.csv')\n",
    "y = df['Price'].values\n",
    "x1 = df['Speed'].values\n",
    "x2 = np.log(df['HardDrive'].values)\n",
    "N = len(y)\n",
    "\n",
    "def log_prior(theta):\n",
    "    alpha, beta1, beta2, sigma = theta\n",
    "    if sigma <= 0: return -np.inf # Constraint: sigma > 0\n",
    "    \n",
    "    # Weakly informative priors\n",
    "    lp = -0.5 * (alpha / 1000)**2 \n",
    "    lp -= 0.5 * (beta1 / 100)**2 \n",
    "    lp -= 0.5 * (beta2 / 500)**2 \n",
    "    lp -= 0.5 * (sigma / 500)**2\n",
    "    return lp\n",
    "\n",
    "def log_likelihood(theta, x1, x2, y):\n",
    "    alpha, beta1, beta2, sigma = theta\n",
    "    if sigma <= 0: return -np.inf\n",
    "    \n",
    "    mu = alpha + beta1 * x1 + beta2 * x2\n",
    "    # Log-Likelihood for Normal Distribution.\n",
    "    ll = -N * np.log(sigma) - np.sum((y - mu)**2) / (2 * sigma**2)\n",
    "    return ll\n",
    "\n",
    "def log_posterior(theta, x1, x2, y):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp): return -np.inf\n",
    "    return lp + log_likelihood(theta, x1, x2, y)\n",
    "\n",
    "n_samples = 20000\n",
    "burn_in = 5000\n",
    "\n",
    "# Initial guess.\n",
    "current_theta = np.array([-45.0, 4.0, 350.0, 500.0]) \n",
    "current_log_post = log_posterior(current_theta, x1, x2, y)\n",
    "\n",
    "chain = np.zeros((n_samples, 4))\n",
    "proposal_scales = np.array([50.0, 0.5, 10.0, 10.0]) # Tuned step sizes\n",
    "accepted = 0\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in range(n_samples):\n",
    "    # Propose new parameters\n",
    "    proposal = current_theta + np.random.normal(0, 1, 4) * proposal_scales\n",
    "    proposed_log_post = log_posterior(proposal, x1, x2, y)\n",
    "    \n",
    "    # Calculate acceptance probability\n",
    "    log_ratio = proposed_log_post - current_log_post\n",
    "    if np.log(np.random.rand()) < log_ratio:\n",
    "        current_theta = proposal\n",
    "        current_log_post = proposed_log_post\n",
    "        accepted += 1\n",
    "    chain[i] = current_theta\n",
    "\n",
    "# 4. Results\n",
    "posterior_samples = chain[burn_in:]\n",
    "means = np.mean(posterior_samples, axis=0)\n",
    "ci_lower = np.percentile(posterior_samples, 2.5, axis=0)\n",
    "ci_upper = np.percentile(posterior_samples, 97.5, axis=0)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Parameter': ['alpha', 'beta1', 'beta2', 'sigma'],\n",
    "    'Mean': means,\n",
    "    '95% CI Lower': ci_lower,\n",
    "    '95% CI Upper': ci_upper\n",
    "})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f812e441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% HDI for Beta1: (np.float64(2.0131959212706088), np.float64(6.545007604187195))\n",
      "95% HDI for Beta2: (np.float64(278.01208117382487), np.float64(431.32374448437326))\n"
     ]
    }
   ],
   "source": [
    "# b)\n",
    "\n",
    "def compute_hdi(samples, credible_mass=0.95):\n",
    "    sorted_samples = np.sort(samples)\n",
    "    n_samples = len(sorted_samples)\n",
    "    interval_idx_inc = int(np.floor(credible_mass * n_samples))\n",
    "    n_intervals = n_samples - interval_idx_inc\n",
    "    interval_width = sorted_samples[interval_idx_inc:] - sorted_samples[:n_intervals]\n",
    "    min_idx = np.argmin(interval_width)\n",
    "    hdi_min = sorted_samples[min_idx]\n",
    "    hdi_max = sorted_samples[min_idx + interval_idx_inc]\n",
    "    return hdi_min, hdi_max\n",
    "\n",
    "beta1_samples = posterior_samples[:, 1]\n",
    "beta2_samples = posterior_samples[:, 2]\n",
    "\n",
    "hdi_beta1 = compute_hdi(beta1_samples)\n",
    "hdi_beta2 = compute_hdi(beta2_samples)\n",
    "\n",
    "print(f\"95% HDI for Beta1: {hdi_beta1}\")\n",
    "print(f\"95% HDI for Beta2: {hdi_beta2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff83872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
